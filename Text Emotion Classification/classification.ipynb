{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d891c7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ive been feeling a little burdened lately wasn...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Emotions\n",
       "0  i can go from feeling so hopeless to so damned...  sadness\n",
       "1   im grabbing a minute to post i feel greedy wrong    anger\n",
       "2  i am ever feeling nostalgic about the fireplac...     love\n",
       "3                               i am feeling grouchy    anger\n",
       "4  ive been feeling a little burdened lately wasn...  sadness"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "data = pd.read_csv('Dataset/train.txt', sep=';')\n",
    "data.columns = ['Text', 'Emotions']  \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'].dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc07daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['Text'].tolist()\n",
    "emotions = data['Emotions'].tolist()\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e386d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f29a50",
   "metadata": {},
   "source": [
    "# Understanding pad_sequences\n",
    "\n",
    "`pad_sequences` is a utility function from TensorFlow's Keras preprocessing module that standardizes the length of sequences (like tokenized text) for neural network processing.\n",
    "\n",
    "## Why it's necessary:\n",
    "\n",
    "1. **Uniform Input Size**: Neural networks require fixed-size inputs, but text documents naturally vary in length.\n",
    "\n",
    "2. **Batch Processing**: To efficiently process data in batches, all sequences in a batch must have the same length.\n",
    "\n",
    "## Key Parameters:\n",
    "\n",
    "- **maxlen**: Maximum sequence length (longer sequences are truncated, shorter ones are padded)\n",
    "- **padding**: Where to add padding ('pre' or 'post')\n",
    "- **truncating**: Where to truncate ('pre' or 'post')\n",
    "- **value**: Padding value (default is 0)\n",
    "\n",
    "## Example visualization below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23274361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sequences:\n",
      "Length: 5, Sequence: [1, 2, 3, 4, 5]\n",
      "Length: 2, Sequence: [1, 2]\n",
      "Length: 10, Sequence: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "After default padding (pre, maxlen=longest):\n",
      "Length: 10, Sequence: [0 0 0 0 0 1 2 3 4 5]\n",
      "Length: 10, Sequence: [0 0 0 0 0 0 0 0 1 2]\n",
      "Length: 10, Sequence: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "With maxlen=7 and padding='post':\n",
      "Length: 7, Sequence: [1 2 3 4 5 0 0]\n",
      "Length: 7, Sequence: [1 2 0 0 0 0 0]\n",
      "Length: 7, Sequence: [ 4  5  6  7  8  9 10]\n",
      "\n",
      "With maxlen=4 and truncating='pre':\n",
      "Length: 4, Sequence: [2 3 4 5]\n",
      "Length: 4, Sequence: [0 0 1 2]\n",
      "Length: 4, Sequence: [ 7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "# Example demonstrating pad_sequences with some sample sentences\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Example sequences of different lengths (after tokenization)\n",
    "sample_sequences = [\n",
    "    [1, 2, 3, 4, 5],               # 5 tokens\n",
    "    [1, 2],                         # 2 tokens\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # 10 tokens\n",
    "]\n",
    "\n",
    "print(\"Original sequences:\")\n",
    "for seq in sample_sequences:\n",
    "    print(f\"Length: {len(seq)}, Sequence: {seq}\")\n",
    "\n",
    "# Padding with default settings (pad with 0s at the beginning)\n",
    "padded_sequences = pad_sequences(sample_sequences)\n",
    "print(\"\\nAfter default padding (pre, maxlen=longest):\")\n",
    "for seq in padded_sequences:\n",
    "    print(f\"Length: {len(seq)}, Sequence: {seq}\")\n",
    "\n",
    "# Padding with custom maxlen and post padding\n",
    "padded_sequences = pad_sequences(sample_sequences, maxlen=7, padding='post')\n",
    "print(\"\\nWith maxlen=7 and padding='post':\")\n",
    "for seq in padded_sequences:\n",
    "    print(f\"Length: {len(seq)}, Sequence: {seq}\")\n",
    "\n",
    "# Padding with custom maxlen and truncating\n",
    "padded_sequences = pad_sequences(sample_sequences, maxlen=4, truncating='pre')\n",
    "print(\"\\nWith maxlen=4 and truncating='pre':\")\n",
    "for seq in padded_sequences:\n",
    "    print(f\"Length: {len(seq)}, Sequence: {seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "283d043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sequence length: 19.2\n",
      "Maximum sequence length: 66\n",
      "Minimum sequence length: 2\n",
      "Median sequence length: 17.0\n",
      "\n",
      "Using maxlen=41 (95th percentile)\n",
      "\n",
      "Shape of padded_sequences: (15999, 41)\n",
      "All sequences now have the same length: 41\n",
      "\n",
      "Original sequence length: 47\n",
      "Padded sequence length: 41\n",
      "Truncated: 6 tokens removed\n",
      "\n",
      "Original sequence length: 27\n",
      "Padded sequence length: 41\n",
      "Padding added: 14 zeros\n",
      "\n",
      "Original sequence length: 28\n",
      "Padded sequence length: 41\n",
      "Padding added: 13 zeros\n"
     ]
    }
   ],
   "source": [
    "# Apply pad_sequences to our text data sequences\n",
    "\n",
    "# First, let's see the length distribution of our sequences\n",
    "seq_lengths = [len(seq) for seq in sequences]\n",
    "\n",
    "print(f\"Average sequence length: {np.mean(seq_lengths):.1f}\")\n",
    "print(f\"Maximum sequence length: {max(seq_lengths)}\")\n",
    "print(f\"Minimum sequence length: {min(seq_lengths)}\")\n",
    "print(f\"Median sequence length: {np.median(seq_lengths):.1f}\")\n",
    "\n",
    "# Let's choose a maxlen that covers most of our data\n",
    "# A common approach is to use a length that covers 95-99% of your sequences\n",
    "maxlen = int(np.percentile(seq_lengths, 95))\n",
    "print(f\"\\nUsing maxlen={maxlen} (95th percentile)\")\n",
    "\n",
    "# Pad our sequences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "print(f\"\\nShape of padded_sequences: {padded_sequences.shape}\")\n",
    "print(f\"All sequences now have the same length: {padded_sequences.shape[1]}\")\n",
    "\n",
    "# Let's look at a couple of examples to see the effect\n",
    "import random\n",
    "for _ in range(3):\n",
    "    idx = random.randint(0, len(sequences)-1)\n",
    "    print(f\"\\nOriginal sequence length: {len(sequences[idx])}\")\n",
    "    print(f\"Padded sequence length: {len(padded_sequences[idx])}\")\n",
    "    if len(sequences[idx]) < maxlen:\n",
    "        print(f\"Padding added: {maxlen - len(sequences[idx])} zeros\")\n",
    "    elif len(sequences[idx]) > maxlen:\n",
    "        print(f\"Truncated: {len(sequences[idx]) - maxlen} tokens removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320b599",
   "metadata": {},
   "source": [
    "## Why pad_sequences is Critical for Model Training\n",
    "\n",
    "### Technical Reasons:\n",
    "\n",
    "1. **Shape Consistency**: Neural networks expect inputs of consistent dimensions\n",
    "2. **Batch Processing Efficiency**: GPUs/TPUs process batches faster when all inputs have the same shape\n",
    "3. **Tensor Operations**: TensorFlow/Keras operations require regular tensors, not ragged arrays\n",
    "\n",
    "### Effect on Model Performance:\n",
    "\n",
    "1. **Information Preservation**: Setting appropriate `maxlen` preserves important content while removing noise\n",
    "2. **Padding Strategy**: `padding='post'` is often better for text as most important words come earlier\n",
    "3. **Memory Usage**: Too large `maxlen` can waste memory and slow training\n",
    "\n",
    "### In Text Emotion Classification:\n",
    "\n",
    "For our text emotion classifier, pad_sequences is essential because:\n",
    "- Emotions can be expressed in texts of varying lengths\n",
    "- The standardized sequence length allows the model to learn patterns regardless of original text length\n",
    "- The embedding layer (which follows) expects fixed-length sequences as input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
